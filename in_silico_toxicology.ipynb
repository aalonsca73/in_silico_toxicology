{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aalonsca73/in_silico_toxicology/blob/main/in_silico_toxicology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fastapi kaleido python-multipart uvicorn pubchempy rdkit mordred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es9X6d84STiX",
        "outputId": "83a92973-bd9a-4288-d42e-651e6fbd5177"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.104.0-py3-none-any.whl (92 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/92.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m92.2/92.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pubchempy in /usr/local/lib/python3.10/dist-packages (1.0.4)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.9.1)\n",
            "Requirement already satisfied: mordred in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.7.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (1.10.13)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.8.0 (from fastapi)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Requirement already satisfied: six==1.* in /usr/local/lib/python3.10/dist-packages (from mordred) (1.16.0)\n",
            "Requirement already satisfied: networkx==2.* in /usr/local/lib/python3.10/dist-packages (from mordred) (2.8.8)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.1.3)\n",
            "Installing collected packages: kaleido, typing-extensions, python-multipart, h11, uvicorn, starlette, fastapi\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fastapi-0.104.0 h11-0.14.0 kaleido-0.2.1 python-multipart-0.0.6 starlette-0.27.0 typing-extensions-4.8.0 uvicorn-0.23.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK8nRNfCRi0G",
        "outputId": "e00c2da7-75ca-4106-dd05-a2891d5cb62b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [00:16<00:00,  3.93it/s]\n"
          ]
        }
      ],
      "source": [
        "# Define the filename for the Excel file\n",
        "filename = 'llistes.xlsx'\n",
        "\n",
        "# Define the column name to be used as the index.\n",
        "# Set this variable to the name of the column containing the molecule names of interest.\n",
        "index = 'Name'\n",
        "\n",
        "# Import necessary libraries\n",
        "import sys\n",
        "import pubchempy as pcp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
        "from mordred import Calculator, descriptors\n",
        "\n",
        "# Create a descriptor calculator with all available descriptors\n",
        "calc = Calculator(descriptors)\n",
        "\n",
        "# Read the Excel file using pandas\n",
        "df = pd.read_excel(filename,sheet_name=1,header=0)\n",
        "df.set_index(index,inplace=True)\n",
        "\n",
        "# Create a list to store all canonical SMILES\n",
        "SMILES_list = []\n",
        "\n",
        "# Create a list to store molecules not found in PubChem\n",
        "molecules_not_found = []\n",
        "\n",
        "# Iterate through each molecule identifier in the index column to retrieve compound names from PubChem\n",
        "for ids in df.index:\n",
        "    try:\n",
        "        # Fetch the compound name from PubChem\n",
        "        compound_name = pcp.get_compounds(ids,'name')\n",
        "        # Check if compound name is empty (no results)\n",
        "        if not compound_name:\n",
        "            # Use boolean indexing to drop rows with empty compound_name\n",
        "            df.drop(ids,axis=0,inplace=True)\n",
        "            # Add the molecule to the list of molecules_not_found\n",
        "            molecules_not_found.append(ids)\n",
        "        else:\n",
        "            # Extract the first identifier for the compound\n",
        "            first_identifier = compound_name[0].cid\n",
        "            # Fetch the canonical SMILES for the first identifier\n",
        "            first_smiles = pcp.get_compounds(first_identifier,'cid')[0].canonical_smiles\n",
        "            # Add the canonical SMILES to a list called SMILES_list\n",
        "            SMILES_list.append(first_smiles)\n",
        "    except Exception as e:\n",
        "        print(f\"Error for molecule {ids}: {e}\")\n",
        "\n",
        "# Create a DataFrame with molecules not found in PubChem\n",
        "missing_molecules_df = pd.DataFrame(data=molecules_not_found)\n",
        "\n",
        "# Reset the index after dropping rows\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "# Remove duplicate canonical SMILES while preserving order\n",
        "canonical_SMILES = list(dict.fromkeys(SMILES_list))\n",
        "\n",
        "# We create a DataFrame with canonical SMILES\n",
        "smiles_df = pd.DataFrame(data=canonical_SMILES)\n",
        "# Rename the column\n",
        "smiles_df.columns = ['SMILES']\n",
        "# Insert the DataFrame with compound names into the DataFrame with SMILES\n",
        "smiles_df.insert(0,'Name',df['Name'],True)\n",
        "\n",
        "# Create a new list called data to store all properties\n",
        "data = []\n",
        "\n",
        "# Iterate through every SMILES in smiles_df to extract properties of every molecule\n",
        "for molecule in smiles_df['SMILES']:\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(molecule)\n",
        "        data.append(mol)\n",
        "    except:\n",
        "        print(molecule)\n",
        "\n",
        "# Create a new DataFrame called props_df with all obtained molecular properties\n",
        "props_df = calc.pandas(data)\n",
        "\n",
        "# Remove molecular descriptors that are not informative\n",
        "# Delete columns where all values are zero\n",
        "props_df = props_df.loc[:, ~np.all(np.equal(props_df.values, 0), axis=0)]\n",
        "# Delete columns containing non-numeric data\n",
        "props_df = props_df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Merge the DataFrame containing SMILES with the DataFrame containing all properties\n",
        "names_props = pd.concat([smiles_df,props_df],axis=1)\n",
        "\n",
        "# Create a new document with all information\n",
        "names_props.to_csv('molecules_with_properties.csv',index=False)\n",
        "\n",
        "# Create another document with molecules not found in PubChem\n",
        "missing_molecules_df.to_csv('molecules_not_found.csv',index=False)"
      ]
    }
  ]
}