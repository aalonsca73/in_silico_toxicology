{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPB1q3/jA4DPpMAq5Kx3etN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aalonsca73/in_silico_toxicology/blob/main/in_silico_toxicology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pubchempy rdkit mordred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es9X6d84STiX",
        "outputId": "74a320ac-5fc3-4360-bf6b-14d7f26b8acd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pubchempy in /usr/local/lib/python3.10/dist-packages (1.0.4)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.3.3)\n",
            "Collecting mordred\n",
            "  Downloading mordred-1.2.0.tar.gz (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.8/128.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Requirement already satisfied: six==1.* in /usr/local/lib/python3.10/dist-packages (from mordred) (1.16.0)\n",
            "Collecting networkx==2.* (from mordred)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mordred\n",
            "  Building wheel for mordred (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mordred: filename=mordred-1.2.0-py3-none-any.whl size=176721 sha256=0681c1a6f0523429ec0d2c56936efed10b206facc67eb6d2d6981e88062cf06f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/4f/b8/d4c6591f6ac944aaced7865b349477695f662388ad958743c7\n",
            "Successfully built mordred\n",
            "Installing collected packages: networkx, mordred\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mordred-1.2.0 networkx-2.8.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK8nRNfCRi0G",
        "outputId": "edf1acbf-5cad-4551-9076-f5eccee461ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:01<00:00, 10.51it/s]\n"
          ]
        }
      ],
      "source": [
        "# Definition of file name\n",
        "filename = 'aminoacids.txt'\n",
        "\n",
        "# Libraries needed\n",
        "import sys\n",
        "import pubchempy as pcp\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
        "from mordred import Calculator, descriptors\n",
        "\n",
        "# Creation of a descriptor calculator with all descriptors\n",
        "calc = Calculator(descriptors)\n",
        "\n",
        "# We use pandas to read the file we defined previously, which does not have a header.\n",
        "# We're adding a header called 'Compound' to the DataFrame for clarity.\n",
        "df = pd.read_csv(filename,header=None,names=['Compound'])\n",
        "\n",
        "# We create a list to add all SMILES\n",
        "SMILES_list = []\n",
        "\n",
        "# Iterate through each identifier in the 'Compound' column to obtain compound names from PubChem\n",
        "for ids in df['Compound']:\n",
        "    compound_name = pcp.get_compounds(ids,'name')\n",
        "\n",
        "    # Once we have compound names, iterate through every name to obtain canonical SMILES from PubChem\n",
        "    for name in compound_name:\n",
        "        smiles = name.canonical_smiles\n",
        "        # Then, we add canonical SMILES to a list called SMILES_list\n",
        "        SMILES_list.append(smiles)\n",
        "\n",
        "# We turn the list into a dictionary to remove all repeated canonical SMILES while maintaining order\n",
        "canonical_SMILES = list(dict.fromkeys(SMILES_list))\n",
        "\n",
        "# We create a DataFrame with canonical SMILES\n",
        "smiles_df = pd.DataFrame(data=canonical_SMILES)\n",
        "# Rename the column\n",
        "smiles_df.columns = ['SMILES']\n",
        "# Insert the DataFrame with compound names into the DataFrame with SMILES\n",
        "smiles_df.insert(0,'Compound',df['Compound'],True)\n",
        "\n",
        "# We create a new list called data to add all properties\n",
        "data = []\n",
        "\n",
        "# We iterate through every SMILES in smiles_df to get properties of every molecule\n",
        "for molecule in smiles_df['SMILES']:\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(molecule)\n",
        "        data.append(mol)\n",
        "    except:\n",
        "        print(molecule)\n",
        "\n",
        "# We define a new DataFrame called props_df with all properties we obtained before\n",
        "props_df = calc.pandas(data)\n",
        "\n",
        "# We merge the DataFrame containing SMILES with the DataFrame containing all properties\n",
        "names_props = pd.concat([smiles_df,props_df],axis=1)\n",
        "\n",
        "# We create a new document with all information\n",
        "names_props.to_csv('molecules_with_properties.csv',index=False)"
      ]
    }
  ]
}