{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aalonsca73/in_silico_toxicology/blob/main/in_silico_toxicology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fastapi kaleido python-multipart uvicorn pubchempy rdkit mordred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es9X6d84STiX",
        "outputId": "38c72350-08e6-463b-ed7d-d4e0d97e2eef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/92.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pubchempy\n",
            "  Downloading PubChemPy-1.0.4.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mordred\n",
            "  Downloading mordred-1.2.0.tar.gz (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.8/128.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.7.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (1.10.13)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.8.0 (from fastapi)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Requirement already satisfied: six==1.* in /usr/local/lib/python3.10/dist-packages (from mordred) (1.16.0)\n",
            "Collecting networkx==2.* (from mordred)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.1.3)\n",
            "Building wheels for collected packages: pubchempy, mordred\n",
            "  Building wheel for pubchempy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pubchempy: filename=PubChemPy-1.0.4-py3-none-any.whl size=13820 sha256=72d7c77d4f060a96c26d0e182e68c43c856eaad159f2599df6389dc3035378a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/7c/45/18a0671e3c3316966ef7ed9ad2b3f3300a7e41d3421a44e799\n",
            "  Building wheel for mordred (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mordred: filename=mordred-1.2.0-py3-none-any.whl size=176721 sha256=ab9a6220903f72d78974bf785a6b780ff0dee5f5341236a72e9ca2a5d678b239\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/4f/b8/d4c6591f6ac944aaced7865b349477695f662388ad958743c7\n",
            "Successfully built pubchempy mordred\n",
            "Installing collected packages: pubchempy, kaleido, typing-extensions, rdkit, python-multipart, networkx, h11, uvicorn, starlette, mordred, fastapi\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2\n",
            "    Uninstalling networkx-3.2:\n",
            "      Successfully uninstalled networkx-3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fastapi-0.104.1 h11-0.14.0 kaleido-0.2.1 mordred-1.2.0 networkx-2.8.8 pubchempy-1.0.4 python-multipart-0.0.6 rdkit-2023.9.1 starlette-0.27.0 typing-extensions-4.8.0 uvicorn-0.23.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK8nRNfCRi0G",
        "outputId": "be7196c8-2035-46bd-c1ec-bc9ca2cc8f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 71/71 [00:19<00:00,  3.69it/s]\n"
          ]
        }
      ],
      "source": [
        "# Define the filename for the Excel file\n",
        "filename = 'llistes.xlsx'\n",
        "\n",
        "# Define the column name to be used as the index.\n",
        "# Set this variable to the name of the column containing the molecule names of interest.\n",
        "index = 'Name'\n",
        "\n",
        "# Define the threshold percentage of zeros to drop columns with a higher percentage.\n",
        "percent_zeros = 0.7\n",
        "\n",
        "# Import necessary libraries\n",
        "import sys\n",
        "import pubchempy as pcp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
        "from mordred import Calculator, descriptors\n",
        "\n",
        "# Create a descriptor calculator with all available descriptors\n",
        "calc = Calculator(descriptors)\n",
        "\n",
        "# Read the Excel file using pandas\n",
        "df = pd.read_excel(filename,sheet_name=1,header=0)\n",
        "df.set_index(index,inplace=True)\n",
        "\n",
        "# Create a list to store all canonical SMILES\n",
        "SMILES_list = []\n",
        "\n",
        "# Create a list to store molecules not found in PubChem\n",
        "molecules_not_found = []\n",
        "\n",
        "# Create a DataFrame to store found molecules\n",
        "found_molecules_df = pd.DataFrame(columns=['Name','SMILES'])\n",
        "\n",
        "# Create a new list called data to store all properties\n",
        "data = []\n",
        "\n",
        "# Iterate through each molecule identifier in the index column\n",
        "for ids in df.index:\n",
        "    try:\n",
        "        # Fetch the compound name from PubChem\n",
        "        compound_name = pcp.get_compounds(ids,'name')\n",
        "        # Check if compound name is empty (no results)\n",
        "        if not compound_name:\n",
        "            # Use boolean indexing to drop rows with empty compound_name\n",
        "            df.drop(ids,axis=0,inplace=True)\n",
        "            # Add the molecule to the list of molecules_not_found\n",
        "            molecules_not_found.append(ids)\n",
        "        else:\n",
        "            # Extract the first identifier for the compound\n",
        "            first_identifier = compound_name[0].cid\n",
        "            # Fetch the canonical SMILES for the first identifier\n",
        "            first_smiles = pcp.get_compounds(first_identifier,'cid')[0].canonical_smiles\n",
        "            # Add the canonical SMILES to a list called SMILES_list\n",
        "            SMILES_list.append(first_smiles)\n",
        "\n",
        "            # Create a DataFrame with found molecules and add it to the found_molecules_df\n",
        "            found_molecule_df = pd.DataFrame(data=[[ids, first_smiles]], columns=['Name', 'SMILES'])\n",
        "            found_molecules_df = pd.concat([found_molecules_df, found_molecule_df], ignore_index=True)\n",
        "\n",
        "            # Extract properties for the molecule\n",
        "            try:\n",
        "                mol = Chem.MolFromSmiles(first_smiles)\n",
        "                data.append(mol)\n",
        "            except:\n",
        "                print(first_smiles)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error for molecule {ids}: {e}\")\n",
        "\n",
        "# Create a DataFrame with molecules not found in PubChem\n",
        "missing_molecules_df = pd.DataFrame(data=molecules_not_found)\n",
        "\n",
        "# Reset the index after dropping rows\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "# Remove duplicate canonical SMILES while preserving order\n",
        "#canonical_SMILES = list(dict.fromkeys(SMILES_list))\n",
        "seen = set()\n",
        "canonical_SMILES = [x for x in SMILES_list if not (x in seen or seen.add(x))]\n",
        "\n",
        "\n",
        "\n",
        "first_smiles_df = pd.DataFrame(data=SMILES_list)\n",
        "canonical_SMILES_df = pd.DataFrame(data=canonical_SMILES)\n",
        "first_smiles_df.to_csv('first_smiles.csv',index=False)\n",
        "canonical_SMILES_df.to_csv('canonical_smiles.csv',index=False)\n",
        "\n",
        "# We create a DataFrame with canonical SMILES\n",
        "smiles_df = pd.DataFrame(data=canonical_SMILES)\n",
        "# Rename the column\n",
        "smiles_df.columns = ['SMILES']\n",
        "# Insert the DataFrame with compound names into the DataFrame with SMILES\n",
        "smiles_df.insert(0,'Name',df['Name'],True)\n",
        "\n",
        "\n",
        "\n",
        "# Iterate through every SMILES in smiles_df to extract properties of every molecule\n",
        "#for molecule in smiles_df['SMILES']:\n",
        "#    try:\n",
        "#        mol = Chem.MolFromSmiles(molecule)\n",
        "#        data.append(mol)\n",
        "#    except:\n",
        "#        print(molecule)\n",
        "\n",
        "# Create a new DataFrame called props_df with all obtained molecular properties\n",
        "props_df = calc.pandas(data)\n",
        "\n",
        "# Remove uninformative molecular descriptors\n",
        "# Delete columns where the percentage of zeros exceeds the specified threshold\n",
        "props_df = props_df.loc[:,(props_df==0).mean()<percent_zeros]\n",
        "# Filter and keep only columns with numeric data\n",
        "props_df = props_df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Merge the DataFrame containing SMILES with the DataFrame containing all properties\n",
        "names_props = pd.concat([found_molecules_df,props_df],axis=1)\n",
        "\n",
        "# Create a new document with all information\n",
        "names_props.to_csv('molecules_with_properties.csv',index=False)\n",
        "\n",
        "# Create another document with molecules not found in PubChem\n",
        "missing_molecules_df.to_csv('molecules_not_found.csv',index=False)"
      ]
    }
  ]
}